# Double Inverted Pendulum RL (dip_rl)

A reinforcement learning project for training agents to balance a double inverted pendulum using function-approximated Q-Learning (LFA) and policy-gradient methods (PPO from Stable-Baselines3). Built with PyBullet, Gymnasium, and ROS2-compatible simulation structure.

---

## ğŸ§  Features

- âœ… **Custom Gymnasium Environment** with PyBullet physics.
- âœ… **Proximal Policy Optimization (PPO)** via Stable-Baselines3.
- âœ… **Q-Learning with Linear Function Approximation (LFA)**.
- âœ… **Training Mode Toggle**: switch between deterministic dev mode and randomized robust mode.
- âœ… **Evaluation Utilities**: success rate, reward curves, and TensorBoard metrics.
- âœ… **Modular Callbacks**: checkpointing, early stopping, custom TensorBoard logging.

---

## ğŸš€ Getting Started
### 1. Install Dependencies
```bash
pip install -r requirements.txt
```

### 2. Train PPO Agent
```bash
python train.py --mode dev       # or --mode robust
```

### 3. Run LFA-Based Q-Learning
```bash
python q_learning_lfa.py --mode dev       # or --mode robust
```
---


## ğŸ“ Repository Structure

```bash
dip_rl/
â”œâ”€â”€ dip_env/                         # Custom Gymnasium-compatible environment
â”‚   â””â”€â”€ dip_env.py
â”œâ”€â”€ models/                          # URDF model of double pendulum
â”‚   â””â”€â”€ double_pendulum.urdf
â”œâ”€â”€ logs/                            # TensorBoard logs, checkpoints, eval results
â”œâ”€â”€ train.py                         # PPO training script (with toggleable mode)
â”œâ”€â”€ q_learning_lfa.py                # Q-Learning (LFA) implementation
â””â”€â”€ README.md
```
---

## ğŸ“Œ References
Gustafsson et al., Control of Inverted Double Pendulum using Reinforcement Learning

---

## ğŸ‘¨â€ğŸ”¬ Maintainer Info
- Maintainer: Samuel Chien

- Lab: Mechatronics and Controls Laboratory, UCLA

- Email: samuelbruin0618@g.ucla.edu
